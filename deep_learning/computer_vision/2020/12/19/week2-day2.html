<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Week 2, Day 2 (Introduction to Artificial Intelligence and Computer Vision) | McE-51069</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Week 2, Day 2 (Introduction to Artificial Intelligence and Computer Vision)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Welcome to second day (Week 2) of the McE-51069 course. In this week, we will walk you through with basic Knowledge on Deep learning and Computer Vision." />
<meta property="og:description" content="Welcome to second day (Week 2) of the McE-51069 course. In this week, we will walk you through with basic Knowledge on Deep learning and Computer Vision." />
<link rel="canonical" href="https://ytu-cvlab.github.io/mce-51069/deep_learning/computer_vision/2020/12/19/week2-day2.html" />
<meta property="og:url" content="https://ytu-cvlab.github.io/mce-51069/deep_learning/computer_vision/2020/12/19/week2-day2.html" />
<meta property="og:site_name" content="McE-51069" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-19T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://ytu-cvlab.github.io/mce-51069/deep_learning/computer_vision/2020/12/19/week2-day2.html","@type":"BlogPosting","headline":"Week 2, Day 2 (Introduction to Artificial Intelligence and Computer Vision)","dateModified":"2020-12-19T00:00:00-06:00","datePublished":"2020-12-19T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ytu-cvlab.github.io/mce-51069/deep_learning/computer_vision/2020/12/19/week2-day2.html"},"description":"Welcome to second day (Week 2) of the McE-51069 course. In this week, we will walk you through with basic Knowledge on Deep learning and Computer Vision.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/mce-51069/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ytu-cvlab.github.io/mce-51069/feed.xml" title="McE-51069" /><link rel="shortcut icon" type="image/x-icon" href="/mce-51069/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/mce-51069/">McE-51069</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/mce-51069/about/">About Us</a><a class="page-link" href="/mce-51069/search/">Search</a><a class="page-link" href="/mce-51069/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Week 2, Day 2 (Introduction to Artificial Intelligence and Computer Vision)</h1><p class="page-description">Welcome to second day (Week 2) of the McE-51069 course. In this week, we will walk you through with basic Knowledge on Deep learning and Computer Vision.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-19T00:00:00-06:00" itemprop="datePublished">
        Dec 19, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/mce-51069/categories/#deep_learning">deep_learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/mce-51069/categories/#computer_vision">computer_vision</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Review">Review </a></li>
<li class="toc-entry toc-h1"><a href="#Adam-Optimizer">Adam Optimizer </a></li>
<li class="toc-entry toc-h1"><a href="#Dataset">Dataset </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Train-/-Validation-/-Test">Train / Validation / Test </a></li>
<li class="toc-entry toc-h2"><a href="#Bias-and-Variance">Bias and Variance </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Regularization">Regularization </a>
<ul>
<li class="toc-entry toc-h2"><a href="#$L_1$-and-$L_2$-Regularizaiton">$L_1$ and $L_2$ Regularizaiton </a></li>
<li class="toc-entry toc-h2"><a href="#Dropout-and-Cutout">Dropout and Cutout </a></li>
<li class="toc-entry toc-h2"><a href="#Data-Augmentation">Data Augmentation </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Framework">Framework </a></li>
<li class="toc-entry toc-h1"><a href="#Platform">Platform </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-19-week2-day2.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Review">
<a class="anchor" href="#Review" aria-hidden="true"><span class="octicon octicon-link"></span></a>Review<a class="anchor-link" href="#Review"> </a>
</h1>
<p>In the last post, we introduce the basic components in building a neural network.</p>
<ol>
<li>Weights and Bias</li>
<li>Activation Functions</li>
<li>Loss Function</li>
<li>Optimization (Gradient Descent)</li>
</ol>
<p>And the process in which an input data pass through the network, calculating the loss is called the forward propagation and with that loss value update the model parameters is called backward propagation.</p>
<p><img src="/mce-51069/images/copied_from_nb/animations/revision.gif" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Adam-Optimizer">
<a class="anchor" href="#Adam-Optimizer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adam Optimizer<a class="anchor-link" href="#Adam-Optimizer"> </a>
</h1>
<p>Now, we will introduce Adam optimizer, which is also known as the adaptive moment estimation optimizer.</p>
<p>Let's recall the Gradient Descent Optimizer:</p>
<p>$W = W-\alpha \frac{dL}{dW}$, in which $\alpha$ is called the learning rate, which is a constance or decaying learning rate, depanding on the number of epoch trained.</p>
<p>The weight value is updated according to the loss value. But, the loss value from the model can be instable at first, due to dataset randomness, or dropout in model. So, instead of directly update the new $\frac{dL}{dW}$, we will update the exponentially weighted average of $\frac{dL}{dW}$, which state that, the model is updated according to the past and current $\frac{dL}{dW}$. The result is smoother update in the weight value respect to the loss.</p>
<blockquote>
<p>$V_t = \beta*V_{t-1} + (1-\beta)dW$<br>
$W = W - \alpha V_{dW}$</p>
</blockquote>
<p><img src="/mce-51069/images/copied_from_nb/animations/gradient_descent_with_momentum.gif" alt=""></p>
<p>Like that, another method called RMS Prop further smooth out the training procedure.</p>
<blockquote>
<p>$S_{dW} = \beta_2*S_{dW} + (1-\beta_2)dW^2$<br>
$W = W - \alpha\frac{dW}{\sqrt{S_{dW}} + \epsilon}$</p>
</blockquote>
<p>By combining the two equations above, the eqaution for Adam optimizer become:<br>$W = W - \alpha\frac{V_{dW}^{corrected}}{\sqrt{S_dW^{corrected} }+ \varepsilon}
$</p>
<p>There are two hyper-parameters in this equation and the author of the adam optimizer suggests the value for $\beta_1$ to be 0.9 and $\beta_2$ to be 0.99.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Dataset">
<a class="anchor" href="#Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset<a class="anchor-link" href="#Dataset"> </a>
</h1>
<p>There are two main factors in making a great AI model.</p>
<ol>
<li>The algorithms (model architecture, loss function, optimizer)</li>
<li>Dataset or environment in reinforcement learning.</li>
</ol>
<p>Dataset is like the fuel for our model. If the dataset is well processed, and contain rich information, the performance of the model can go up accordingly.</p>
<p>When we get a dataset and want to use it for training the model, we will first have to separate the dataset into three parts:</p>
<ol>
<li>Training Dataset (Dataset used to train the model)</li>
<li>Validation Dataset (Dataset used for hyper-parameters tunning)</li>
<li>Testing Dataset (Dataset used for evaluating model performance)</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-/-Validation-/-Test">
<a class="anchor" href="#Train-/-Validation-/-Test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train / Validation / Test<a class="anchor-link" href="#Train-/-Validation-/-Test"> </a>
</h2>
<p>Today is a big data era, where we can easily get accessed to millions of dataset. Typcially, when training a small simple network, a small dataset is enough, but with deep learning, we can construct more complex model with ease and so the need for data is becoming larger and larger. Typically, we can divide these data into 3 parts with each percentage of 70/15/15. But, if the dataset is large, let's say 60,000 images in CIFAR10 dataset, 10 percent of the dataset already contain 6,000 images. And that is enough to test our model performance. So, we often divide the dataset into 80/10/10. But it is up to you.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bias-and-Variance">
<a class="anchor" href="#Bias-and-Variance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bias and Variance<a class="anchor-link" href="#Bias-and-Variance"> </a>
</h2>
<p>Clean and well structured data can help model to learn faster and better. But in real world, it is really hard to get dataset that is clean. Often, what we have to encounter are the datasets that have outliers, wrong data point. So, when training, we want our model to be robust of such outlier. For that, we will introduce two ideas: Bias and Variance.</p>
<p><img src="/mce-51069/images/copied_from_nb/images/bias.jpeg" alt="">
<em>Fig : Model is undertrain</em></p>
<p><img src="/mce-51069/images/copied_from_nb/images/variance.jpeg" alt="">
<em>Fig : Model is overtrain</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Regularization">
<a class="anchor" href="#Regularization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regularization<a class="anchor-link" href="#Regularization"> </a>
</h1>
<p>Underfitting can be solved by simply making the model to be more complex (adding more layers), able to learn non-linearity. But, regarding about the overfitting, we have to make adjustment, either to the model, or to dataset. This process of preventing the overfitting of the model is called regularization.</p>
<p>Typical regularization methods contain:<br></p>
<ul>
<li>Model side:<ol>
<li>L1 and L2 regularization</li>
<li>Drop out</li>
</ol>
</li>
<li>Dataset side:<ol>
<li>Data Augmentation</li>
</ol>
</li>
</ul>
<p>The regularization on the model side, is basically making the model to be simple, opposite to fixing underfitting problem, by turning some neurons in the model off. We will discuss more about regularization method in the following section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="$L_1$-and-$L_2$-Regularizaiton">
<a class="anchor" href="#%24L_1%24-and-%24L_2%24-Regularizaiton" aria-hidden="true"><span class="octicon octicon-link"></span></a>$L_1$ and $L_2$ Regularizaiton<a class="anchor-link" href="#%24L_1%24-and-%24L_2%24-Regularizaiton"> </a>
</h2>
<p>$L_1$ and $L_2$ regularization is done by adding penalty to the cost function: $J$</p>
<p>The original cost function is:<br></p>
<p>$J = \frac{1}{m}\sum_{m=0}^i L$</p>
<p>In $L_1$ regularization, the cost function is modified to :<br></p>
<p>$J = \frac{1}{m}\sum_{m=0}^i (L +\frac{\lambda}{2m}W) $</p>
<p>In $L_2$ regularization, the cost function is modified to :<br></p>
<p>$J = \frac{1}{m}\sum_{m=0}^i (L +\frac{\lambda}{2m}W^TW) $</p>
<p>To reduce the cost value, the regularization part must be kept small, and so the weight value will be small or kept to zero, which is the same as turning the neuron cell off.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dropout-and-Cutout">
<a class="anchor" href="#Dropout-and-Cutout" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dropout and Cutout<a class="anchor-link" href="#Dropout-and-Cutout"> </a>
</h2>
<p>Dropout is one of the most commonly used method for regularization. Here, we will take cutout as example and explain why dropout work.</p>
<p>Neural network work by detecting the features in the dataset. And since some of the features are more importance than the others, the neural network tends to focus more on these features and ignore other features. That may lead to bias, biased to some features in the dataset.</p>
<p><img src="/mce-51069/images/copied_from_nb/images/importance.jpeg" alt='"Some features are more importance"'></p>
<p>Like the figure show above, the model will most likely focus on the face part of the dataset. To avoid that, when training, we can introduce some random cutout of the dataset. Cutout is the data augmentation method, in which random part of the input are being cropped out.</p>
<p><img src="/mce-51069/images/copied_from_nb/images/cutout.jpeg" alt='"Cutout"'></p>
<p>This way, our model is forced to learn other features aside from the most importance feature. This is on the dataset side. For the model side, this is carried out by dropout, which randomly shut down some of the neurons in training process. In convolutional neural network, this process is called dropblock.</p>
<p><img src="/mce-51069/images/copied_from_nb/images/dropblock.jpeg" alt='"Dropblock"'></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Augmentation">
<a class="anchor" href="#Data-Augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Augmentation<a class="anchor-link" href="#Data-Augmentation"> </a>
</h2>
<p>Data augmentation is one of the most used regularization method. And this method can greatly effect model training performance. Data augmentation means making extra dataset from the existing dataset. For example, in image dataset, even thought the object in the image is the same, the pixel position, the pixel value can change dramatically. By the methods to augment the data, it can be divided into two types:</p>
<p><img src="/mce-51069/images/copied_from_nb/images/augmentation.jpeg" alt=""></p>
<p>Geometric distortion is achieved by changing the pixel coordinates: Rotation, Translation. Photometric distortion is achieved by changing the pixel value: Contrast, Brightness, etc.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Framework">
<a class="anchor" href="#Framework" aria-hidden="true"><span class="octicon octicon-link"></span></a>Framework<a class="anchor-link" href="#Framework"> </a>
</h1>
<p>There are many frameworks for building the deep learning model. In this course, we will use <a href="https://pytorch.org">Pytorch</a>, which is a open source machine learning library based on Torch library. Pytorch has recently gain more popularity with researchers and in production lines. So, there are many resources for learning deep learning model. And it is more friendly than tensorflow, which is also a open source deep learning library.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Platform">
<a class="anchor" href="#Platform" aria-hidden="true"><span class="octicon octicon-link"></span></a>Platform<a class="anchor-link" href="#Platform"> </a>
</h1>
<p>For training a deep neural network, it is better to have a GPU for faster training.
<img src="/mce-51069/images/copied_from_nb/images/cpu_gpu.jpeg" alt=""></p>
<p>GPU, which can process more parallel task than CPU, are great arsenel in training neural network. And because not all students have a descent GPU in their comptuer, we will use <a href="https://colab.research.google.com/">google colaboratory</a>, which is a jupyter-like development platform where we can get accessed to free GPU.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/mce-51069/deep_learning/computer_vision/2020/12/19/week2-day2.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/mce-51069/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/mce-51069/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/mce-51069/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Study Artificial Intelligence from Theory-oriented to Practical Approach</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://www.facebook.com/https%3A%2F%2Fwww.facebook.com%2Fgroups%2F467439787576222" title="https://www.facebook.com/groups/467439787576222"><svg class="svg-icon grey"><use xlink:href="/mce-51069/assets/minima-social-icons.svg#facebook"></use></svg></a></li><li><a rel="me" href="https://www.youtube.com/https%3A%2F%2Fwww.youtube.com%2Fchannel%2FUCDFhKEbfpxKXVk4Mryh7yhA" title="https://www.youtube.com/channel/UCDFhKEbfpxKXVk4Mryh7yhA"><svg class="svg-icon grey"><use xlink:href="/mce-51069/assets/minima-social-icons.svg#youtube"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
